{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2f26d7f2-f9d9-4862-a1b4-0354e4dfddbe",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "      <th>product_id</th>\n",
       "      <th>user_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>B09XWYG6X1</td>\n",
       "      <td>AFKZENTNBQ7A7V7UXW5JJI6UGRYQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.0</td>\n",
       "      <td>B0BXDLF8TW</td>\n",
       "      <td>AFKZENTNBQ7A7V7UXW5JJI6UGRYQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>B09G2PW8ZG</td>\n",
       "      <td>AFKZENTNBQ7A7V7UXW5JJI6UGRYQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.0</td>\n",
       "      <td>B08CSZDXZY</td>\n",
       "      <td>AFKZENTNBQ7A7V7UXW5JJI6UGRYQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>B0C6V27S6N</td>\n",
       "      <td>AFKZENTNBQ7A7V7UXW5JJI6UGRYQ</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rating  product_id                       user_id\n",
       "0     1.0  B09XWYG6X1  AFKZENTNBQ7A7V7UXW5JJI6UGRYQ\n",
       "1     5.0  B0BXDLF8TW  AFKZENTNBQ7A7V7UXW5JJI6UGRYQ\n",
       "2     2.0  B09G2PW8ZG  AFKZENTNBQ7A7V7UXW5JJI6UGRYQ\n",
       "3     5.0  B08CSZDXZY  AFKZENTNBQ7A7V7UXW5JJI6UGRYQ\n",
       "4     5.0  B0C6V27S6N  AFKZENTNBQ7A7V7UXW5JJI6UGRYQ"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read a single Parquet chunk from your user ratings dataset\n",
    "df_user_ratings = pd.read_parquet(\n",
    "    \"gs://recomviz_home_and_kitchen/datasets/converted_user_ratings/chunk_00000.parquet\",\n",
    "    engine=\"pyarrow\",\n",
    "    storage_options={\"token\": \"cloud\"}  # Required in Vertex AI\n",
    ")\n",
    "\n",
    "# Preview it\n",
    "df_user_ratings.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ebe67af-9475-4983-886b-dcde67eb0f2b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>product_id</th>\n",
       "      <th>description</th>\n",
       "      <th>images</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Set of 4 Irish Coffee Glass Mugs Footed 10.5 o...</td>\n",
       "      <td>B07R3DYMH6</td>\n",
       "      <td>[Set of 12 Footed 10.5 oz. Irish coffee mug th...</td>\n",
       "      <td>{'hi_res': ['https://m.media-amazon.com/images...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Foaming Soap Dispenser Thick Ceramic Foam Hand...</td>\n",
       "      <td>B0BNZ8Q7YT</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'hi_res': ['https://m.media-amazon.com/images...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Tapestry Trading 558W90 90 in. European Lace T...</td>\n",
       "      <td>B01508WQC6</td>\n",
       "      <td>[Features. European Lace Tablecloth. 100 Polye...</td>\n",
       "      <td>{'hi_res': [None], 'large': ['https://m.media-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>jersey seating 2 x Vinyl Air Lift Adjustable S...</td>\n",
       "      <td>B00KKU8HTG</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'hi_res': [None, 'https://m.media-amazon.com/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Chisander 20 Inches Grey with White Super Soft...</td>\n",
       "      <td>B0B61RJ848</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'hi_res': ['https://m.media-amazon.com/images...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  product_id  \\\n",
       "0  Set of 4 Irish Coffee Glass Mugs Footed 10.5 o...  B07R3DYMH6   \n",
       "1  Foaming Soap Dispenser Thick Ceramic Foam Hand...  B0BNZ8Q7YT   \n",
       "2  Tapestry Trading 558W90 90 in. European Lace T...  B01508WQC6   \n",
       "3  jersey seating 2 x Vinyl Air Lift Adjustable S...  B00KKU8HTG   \n",
       "4  Chisander 20 Inches Grey with White Super Soft...  B0B61RJ848   \n",
       "\n",
       "                                         description  \\\n",
       "0  [Set of 12 Footed 10.5 oz. Irish coffee mug th...   \n",
       "1                                                 []   \n",
       "2  [Features. European Lace Tablecloth. 100 Polye...   \n",
       "3                                                 []   \n",
       "4                                                 []   \n",
       "\n",
       "                                              images  \n",
       "0  {'hi_res': ['https://m.media-amazon.com/images...  \n",
       "1  {'hi_res': ['https://m.media-amazon.com/images...  \n",
       "2  {'hi_res': [None], 'large': ['https://m.media-...  \n",
       "3  {'hi_res': [None, 'https://m.media-amazon.com/...  \n",
       "4  {'hi_res': ['https://m.media-amazon.com/images...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_item_metadata = pd.read_parquet(\n",
    "    \"gs://recomviz_home_and_kitchen/datasets/converted_item_metadata/chunk_00000.parquet\",\n",
    "    engine=\"pyarrow\",\n",
    "    storage_options={\"token\": \"cloud\"}\n",
    ")\n",
    "\n",
    "df_item_metadata.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0578a7d2-c7d9-442e-a83a-1b1438ecf82a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1,000,000 rows\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#######################################\n",
    "# Create sample from user ratings data\n",
    "#######################################\n",
    "\n",
    "# List of chunks to load for user ratings (adjust as needed)\n",
    "chunk_paths = [\n",
    "    f\"gs://recomviz_home_and_kitchen/datasets/converted_user_ratings/chunk_{i:05}.parquet\"\n",
    "    for i in range(10)  # adjust this range to control size (e.g., 0–10 chunks)\n",
    "]\n",
    "\n",
    "# Load and concatenate user ratings chunks\n",
    "dfs = [\n",
    "    pd.read_parquet(path, engine=\"pyarrow\", storage_options={\"token\": \"cloud\"})\n",
    "    for path in chunk_paths\n",
    "]\n",
    "\n",
    "full_df_ratings = pd.concat(dfs, ignore_index=True)\n",
    "print(f\"Loaded {len(full_df_ratings):,} rows of user ratings\")\n",
    "\n",
    "# Create a sample of 100,000 rows from the user ratings data\n",
    "sample_ratings_df = full_df_ratings.sample(n=100_000, random_state=42)  # adjust as needed\n",
    "sample_ratings_df.to_parquet(\"large_sample_user_ratings.parquet\", index=False)\n",
    "\n",
    "# Extract unique product_ids from the user ratings sample\n",
    "unique_product_ids = sample_ratings_df['product_id'].unique()\n",
    "print(f\"Number of unique product_ids in sample: {len(unique_product_ids):,}\")\n",
    "\n",
    "###########################################################\n",
    "# Create a consistent sample from item metadata data\n",
    "###########################################################\n",
    "\n",
    "# List of chunks to load for item metadata (adjust as needed)\n",
    "chunk_paths = [\n",
    "    f\"gs://recomviz_home_and_kitchen/datasets/converted_item_metadata/chunk_{i:05}.parquet\"\n",
    "    for i in range(10)  # adjust this range to control size (e.g., 0–10 chunks)\n",
    "]\n",
    "\n",
    "# Load and concatenate item metadata chunks\n",
    "dfs = [\n",
    "    pd.read_parquet(path, engine=\"pyarrow\", storage_options={\"token\": \"cloud\"})\n",
    "    for path in chunk_paths\n",
    "]\n",
    "\n",
    "full_df_item = pd.concat(dfs, ignore_index=True)\n",
    "print(f\"Loaded {len(full_df_item):,} rows of item metadata\")\n",
    "\n",
    "# Filter item metadata so that only items found in the user ratings sample are kept\n",
    "filtered_item_df = full_df_item[full_df_item['product_id'].isin(unique_product_ids)]\n",
    "print(f\"Filtered item metadata contains {len(filtered_item_df):,} rows\")\n",
    "\n",
    "# Optionally, if you want to restrict the sample to a fixed number (e.g., 20,000 rows)\n",
    "if len(filtered_item_df) > 20_000:\n",
    "    sample_item_df = filtered_item_df.sample(n=20_000, random_state=42)  # adjust as needed\n",
    "else:\n",
    "    sample_item_df = filtered_item_df\n",
    "\n",
    "sample_item_df.to_parquet(\"large_sample_item_info.parquet\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b111cfbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#######################################\n",
    "# Use Existing Sample User Ratings Data\n",
    "#######################################\n",
    "\n",
    "# Load the existing sample user ratings file (from your long-run algorithm)\n",
    "sample_ratings_df = pd.read_parquet(\"sample_user_ratings.parquet\")\n",
    "print(f\"Loaded sample user ratings: {len(sample_ratings_df):,} rows\")\n",
    "\n",
    "# Extract unique product IDs from the sample\n",
    "unique_product_ids = sample_ratings_df['product_id'].unique()\n",
    "print(f\"Unique product_ids in sample: {len(unique_product_ids):,}\")\n",
    "\n",
    "######################################################\n",
    "# Create a Consistent Sample from Item Metadata Data\n",
    "######################################################\n",
    "\n",
    "# List of chunks to load for item metadata (adjust the range as needed)\n",
    "chunk_paths = [\n",
    "    f\"gs://recomviz_home_and_kitchen/datasets/converted_item_metadata/chunk_{i:05}.parquet\"\n",
    "    for i in range(10)  # adjust this range (e.g., 0–10 chunks)\n",
    "]\n",
    "\n",
    "# Load and concatenate item metadata chunks\n",
    "dfs = [\n",
    "    pd.read_parquet(path, engine=\"pyarrow\", storage_options={\"token\": \"cloud\"})\n",
    "    for path in chunk_paths\n",
    "]\n",
    "full_df_item = pd.concat(dfs, ignore_index=True)\n",
    "print(f\"Loaded {len(full_df_item):,} rows of item metadata\")\n",
    "\n",
    "# Filter item metadata so that only items with product IDs that appear in the sample user ratings are kept\n",
    "filtered_item_df = full_df_item[full_df_item['product_id'].isin(unique_product_ids)]\n",
    "print(f\"Filtered item metadata contains {len(filtered_item_df):,} rows\")\n",
    "\n",
    "# Optionally, if you want to restrict the sample to a fixed number (e.g., 20,000 rows)\n",
    "if len(filtered_item_df) > 20_000:\n",
    "    sample_item_df = filtered_item_df.sample(n=20_000, random_state=42)\n",
    "else:\n",
    "    sample_item_df = filtered_item_df\n",
    "\n",
    "# Save the filtered sample to a new Parquet file\n",
    "sample_item_df.to_parquet(\"updated_sample_item_info.parquet\", index=False)\n",
    "print(\"Saved filtered item info sample as 'updated_sample_item_info.parquet'\")\n"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m128",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m128"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel) (Local)",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
