{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# %pip install datasets\n",
    "# from datasets import load_dataset\n",
    "\n",
    "# # Load the Amazon Reviews 2023 dataset\n",
    "# dataset = load_dataset(\"McAuley-Lab/Amazon-Reviews-2023\", \"raw_review_Home_and_Kitchen\", trust_remote_code=True)\n",
    "\n",
    "# # Print the dataset splits and details\n",
    "# print(dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# dataset.save_to_disk(\"amazon_reviews_dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import os\n",
    "# from google.cloud import storage\n",
    "\n",
    "# # Set your project and bucket name\n",
    "# bucket_name = 'recomviz_home_and_kitchen'\n",
    "# destination_folder = 'datasets/amazon_reviews_dataset'  # GCS path\n",
    "\n",
    "# # Initialize storage client\n",
    "# client = storage.Client()\n",
    "# bucket = client.bucket(bucket_name)\n",
    "\n",
    "# # Upload function\n",
    "# def upload_folder_to_gcs(local_path, gcs_path):\n",
    "#     for root, _, files in os.walk(local_path):\n",
    "#         for file in files:\n",
    "#             local_file = os.path.join(root, file)\n",
    "#             relative_path = os.path.relpath(local_file, local_path)\n",
    "#             blob_path = os.path.join(gcs_path, relative_path)\n",
    "#             blob = bucket.blob(blob_path)\n",
    "#             blob.upload_from_filename(local_file)\n",
    "#             print(f\"Uploaded {local_file} to {blob_path}\")\n",
    "\n",
    "# # Call the function\n",
    "# upload_folder_to_gcs(\"amazon_reviews_dataset\", destination_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# %pip install google-cloud-storage\n",
    "# from google.cloud import storage\n",
    "# import os\n",
    "\n",
    "# def download_gcs_folder(bucket_name, gcs_folder, local_folder):\n",
    "#     client = storage.Client()\n",
    "#     bucket = client.bucket(bucket_name)\n",
    "\n",
    "#     blobs = bucket.list_blobs(prefix=gcs_folder)\n",
    "\n",
    "#     for blob in blobs:\n",
    "#         # Get local path\n",
    "#         local_path = os.path.join(local_folder, os.path.relpath(blob.name, gcs_folder))\n",
    "\n",
    "#         # Create local directories if needed\n",
    "#         os.makedirs(os.path.dirname(local_path), exist_ok=True)\n",
    "\n",
    "#         # Download the file\n",
    "#         blob.download_to_filename(local_path)\n",
    "#         print(f\"Downloaded {blob.name} to {local_path}\")\n",
    "\n",
    "# # üîÅ Replace with your values:\n",
    "# bucket_name = \"recomviz_home_and_kitchen\"\n",
    "# gcs_folder = \"datasets/amazon_reviews_dataset\"  # GCS path (folder)\n",
    "# local_folder = \"amazon_reviews_dataset\"          # Local target\n",
    "\n",
    "# download_gcs_folder(bucket_name, gcs_folder, local_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14ff57f6a58247b9a06ce15ec4afdbce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading dataset from disk:   0%|          | 0/45 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    full: Dataset({\n",
      "        features: ['rating', 'title', 'text', 'images', 'asin', 'parent_asin', 'user_id', 'timestamp', 'helpful_vote', 'verified_purchase'],\n",
      "        num_rows: 67409944\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "# %pip install datasets\n",
    "import os\n",
    "# %pip install google-cloud-storage\n",
    "from google.cloud import storage\n",
    "from datasets import load_from_disk\n",
    "\n",
    "# Make sure the path is correct for your dataset location on disk\n",
    "dataset = load_from_disk(\"amazon_reviews_dataset\")\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['rating', 'parent_asin', 'user_id'],\n",
      "    num_rows: 67409944\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "user_item_dataset = dataset[\"full\"].select_columns([\"rating\", \"parent_asin\", \"user_id\"])\n",
    "print(user_item_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from datasets import load_from_disk\n",
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100_000\n",
    "total_rows = user_item_dataset.num_rows\n",
    "bucket_path = \"gs://recomviz_home_and_kitchen/datasets/converted_user_ratings\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading user-item ratings in batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 675/675 [04:11<00:00,  2.68it/s]\n"
     ]
    }
   ],
   "source": [
    "# Batch conversion with progress bar\n",
    "for i in tqdm(range(0, total_rows, batch_size), desc=\"Uploading user-item ratings in batches\"):\n",
    "    # Select batch\n",
    "    batch = user_item_dataset.select(range(i, min(i + batch_size, total_rows)))\n",
    "    df = batch.to_pandas()\n",
    "    \n",
    "    # Drop rows with nulls\n",
    "    df = df.dropna(subset=[\"user_id\", \"parent_asin\", \"rating\"])\n",
    "    \n",
    "    # Rename for consistency\n",
    "    df.rename(columns={\"parent_asin\": \"product_id\"}, inplace=True)\n",
    "    \n",
    "    # Save batch as Parquet to GCS\n",
    "    df.to_parquet(\n",
    "        f\"{bucket_path}/chunk_{i//batch_size:05}.parquet\",\n",
    "        index=False,\n",
    "        engine=\"pyarrow\",\n",
    "        storage_options={\"token\": \"cloud\"}  # Works in Vertex AI\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m128",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m128"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel) (Local)",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
